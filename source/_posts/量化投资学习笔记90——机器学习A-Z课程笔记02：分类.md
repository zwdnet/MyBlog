---
title: 量化投资学习笔记90——机器学习A-Z课程笔记02：分类
date: 2020-10-09 14:34:36
tags: [量化投资,分类算法,网络课程,机器学习,学习笔记]
categories: 量化投资
---
第三部分 分类问题
逻辑回归
1.原理
数据因变量只有两个可能取值的离散变量。
模型假设：
Sigmolid函数：p = 1/(1+e^-y)
ln(p/(1-p)) = b0 + b1x
函数值大于0.5和小于0.5分为两类。
2.实操
先加载数据，进行数据预处理，特征缩放，并划分训练集和测试集。
然后训练模型并进行预测。
```python
    # 进行逻辑回归训练
    classifier = LogisticRegression(random_state = 0)
    classifier.fit(x_train, y_train)
    # 用分类器预测测试集结果
    y_pred = classifier.predict(x_test)
    print(y_pred)
```
最后用混淆矩阵来评估分类器。
```python
    # 用混淆矩阵评估分类器    
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
```
结果
[[65 3] 
 [ 8 24]]
接着用图形输出结果
训练集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/01.png)
测试集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/02.png)
支持向量机
1.原理
两个分类最接近的点的距离的垂直平分线作为分类界限。
超平面即比数据维度小一维的图像。
SVM最特别的地方:可以学习到最极端，最特别的个例而得到。
2.实操
跟前面代码基本一样，复制过来改改。
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/03.png)
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/04.png)
```python
    # 进行支持向量机训练
    classifier = SVC(kernel = "linear", random_state = 0)
    classifier.fit(x_train, y_train)
    # 用分类器预测测试集结果
    y_pred = classifier.predict(x_test)
    print(y_pred)
```
改kernel看看。
poly多项式
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/05.png)
rbf
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/06.png)
sigmoid
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/07.png)
核SVM
1.原理
线性核svm的问题:有的数据无法划分，如大小同心圆。
用不同的核函数，将线性不可分的数据利用核函数投射到高维，从而可分。
一个例子:一维直线上的点不可分，投射到二维抛物线上。
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/08.png)
2.核技巧
①rbf核(the Gaussian RBF kernel)
图像类似于三维的正态分布曲面。
可以有多个核函数加减。
按核函数与数据点的距离分类。
②sigmoid核
双曲正切
③多项式核
还有很多不同的核函数。
朴素贝叶斯
1.原理
贝叶斯理论(Bayes' Theorem)
P(A|B) = (P(B|A)P(A))/P(B)
2.朴素贝叶斯分类器
P(A|B)为后验概率，P(A)为先验概率，P(B)为似然率，即特征，P(B|A)为边际似然率。
步骤1：求先验概率 P(A)。
步骤2：求似然率P(X)。
步骤3：求边际似然率P(B|A)。
几个问题:
何谓"朴素"?
一个假设:数据的所有特征是独立的。
多个分类:分到最大概率的那类。
2.实操
训练集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/09.png)
测试集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/10.png)
决策树
1.原理
CART:分类和回归树
不停用水平和垂直线对平面分割，直到一个区域内只有一个分类。
2.实操
如果算法使用了欧式距离，需要对数据进行特征缩放，否则不必进行特征缩放。
(还是要特征缩放的，不然画图有问题)
训练集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/11.png)
测试集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/12.png)
随机森林
1.原理
集合学习:采用多个分类器进行预测，再将分类器进行组合。
第一步，随机从训练集里选择k个数据。
第二步，用k个数据训练决策树。
第三步，重复一二步。形成N颗决策树。
第四步，对于新的数据点，用形成的N颗决策树进行预测，占最大比例的预测结果胜出。
2.实操
训练集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/13.png)
测试集
![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/blog0178-QTLearn/63/14.png)
模型评价
假阳性(一类错误)/假阴性(二类错误)，一般二类错误较严重。
混淆矩阵(confusion matrix)
真阴，假阳
假阴，真阳
由混淆矩阵计算的准确率评价模型可能会有问题，高估模型能力。
累积准确曲线(Cumulative Accuracy Profile)
相当于概率分布。
曲线越凸，越远离随机预测曲线，模型预测能力越强。

代码：https://github.com/zwdnet/MyQuant/tree/master/49


我发文章的三个地方，欢迎大家在朋友圈等地方分享，欢迎点“在看”。
我的个人博客地址：https://zwdnet.github.io
我的知乎文章地址： https://www.zhihu.com/people/zhao-you-min/posts
我的微信个人订阅号：赵瑜敏的口腔医学学习园地


![](https://zymblog-1258069789.cos.ap-chengdu.myqcloud.com/other/wx.jpg)
